<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CGI WEBPAGE ARTICLE</title>
    <link rel = "stylesheet" href = "./style.css">
    <div class="outside">
        
    </div>
</head>
<body>
    <div class = "block" id = "title">
        <h1>A Look into CGI</h1>
    </div>

    <div class = "block" id = "header">
        <h2>Computer-Generated Imagery</h2>
    </div> 

    <div class = "block" id = "paragraph">
        <p>
            Prior to CGI being prevalent in film, virtual reality, personal computing, and gaming, one of the early practical applications of CGI was for aviation and military training namely, the flight simulator. Visual systems developed in flight simulators were also an important precursor to three-dimensional computer graphics and Computer Generated Imagery (CGI) systems today. Namely because the object of flight simulation was to reproduce on the ground the behavior of an aircraft in flight. Much of this reproduction had to do with believable visual synthesis that mimicked reality. Combined with the need to pair virtual synthesis with military-level training requirements, CGI technologies applied in flight simulation were often years ahead of what would have been available in commercial computing or even in high-budget film. Early CGI systems could depict only objects consisting of planar polygons. Advances in algorithms and electronics in flight simulator visual systems and CGI in the 1970s and 1980s influenced many technologies still used in modern CGI adding the ability to superimpose texture over the surfaces as well as transition imagery from one level of detail to the next one in a smooth manner.
        </p>
        <div class="image-container">
            <img src = "imgs/image9.png"style="margin-bottom: 20px;">
            <img src = "imgs/image5.png">
        </div>
    </div>
    

    <div class = "block" id = "header">
        <h2>Broadcast and Live Events</h2>
    </div>  


    <div class = "block var1" id = "paragraph">
        <div class="image-container">
            <img src = "imgs/image8.jpg">
        </div>
        Weather visualizations were the first application of CGI in television. It has now become common in weather casting to display full-motion video of images captured in real time from multiple cameras and other imaging devices. Coupled with 3D graphics symbols and mapped to a common virtual geospatial model, these animated visualizations constitute the first true application of CGI to TV. CGI has become common in sports telecasting. Sports and entertainment venues are provided with see-through and overlay content through tracked camera feeds for enhanced viewing by the audience. Examples include the yellow "first down" line seen in television broadcasts of American football games showing the line the offensive team must cross to receive a first down. CGI is also used in association with football and other sporting events to show commercial advertisements overlaid onto the view of the playing area. Sections of rugby fields and cricket pitches also display sponsored images. Swimming telecasts often add a line across the lanes to indicate the position of the current record holder as a race proceeds to allow viewers to compare the current race to the best performance. Other examples include hockey puck tracking and annotations of racing car performance and snooker ball trajectories.
    </div>

    
    <div class = "block" id = "header">
        <h2>Scenery Generators</h2>
    </div>  
    <div class = "block var1 var2" id = "paragraph">
        <div class="image-container">
            <img src = "imgs/image4.jpg"style="margin-bottom: 20px;">
            <img src = "imgs/image1.jpg"style="float:right;">
        </div>
        Scenery generators are commonly used in movies, animations and video games. For example, Industrial Light & Magic used E-on Vue to create the fictional environments for Pirates of the Caribbean: Dead Man's Chest. In such live-action cases, a 3D model of the generated environment is rendered and blended with live-action footage. Scenery generated by the software may also be used to create completely computer-generated scenes. In the case of animated movies such as Kung Fu Panda, the raw generation is assisted by hand-painting to accentuate subtle details. Environment elements not commonly associated with landscapes, such as ocean waves have also been handled by the software. Scenery generation is used in most 3D-based video-games. These typically use either custom or purchased engines that contain their own scenery generators. For some games, they tend to use a procedurally generated terrain.  These typically use a form of height mapping and use of Perlin noise. This will create a grid that with one point in a 2D coordinate will create the same heightmap as it is pseudo-random, meaning it will result in the same output with the same input. This can then easily be translated into the product 3D image.  These can then be changed from the editor tools in most engines if the terrain will be custom built. With recent developments neural networks can be built to create or texture the terrain based on previously suggested artwork or heightmap data. These would be generated using algorithms that have been able to identify images and similarities between them. With the info the machine can take other heightmaps and render a very similar looking image to the style image. This can be used to create similar images in example a Studio Ghibli or Van Gogh art-style.
    </div>

    <div class = "block" id = "header">
        <h2>Motion Capture in CGI</h2>
    </div>  
    <div class = "block var1 var2" id = "paragraph">
        Motion capture (sometimes referred as mo-cap or mocap, for short) is the process of recording the movement of objects or people. It is used in military, entertainment, sports, medical applications, and for validation of computer vision and robots. In filmmaking and video game development, it refers to recording actions of human actors and using that information to animate digital character models in 2D or 3D computer animation. When it includes face and fingers or captures subtle expressions, it is often referred to as performance capture. In many fields, motion capture is sometimes called motion tracking, but in filmmaking and games, motion tracking usually refers more to match moving. In motion capture sessions, movements of one or more actors are sampled many times per second. Whereas early techniques used images from multiple cameras to calculate 3D positions, often the purpose of motion capture is to record only the movements of the actor, not their visual appearance. This animation data is mapped to a 3D model so that the model performs the same actions as the actor. This process may be contrasted with the older technique of rotoscoping. Camera movements can also be motion captured so that a virtual camera in the scene will pan, tilt or dolly around the stage driven by a camera operator while the actor is performing. At the same time, the motion capture system can capture the camera and props as well as the actor's performance. This allows the computer-generated characters, images and sets to have the same perspective as the video images from the camera. A computer processes the data and displays the movements of the actor, providing the desired camera positions in terms of objects in the set. Retroactively obtaining camera movement data from the captured footage is known as match moving or camera tracking. The first virtual actor animated by motion-capture was produced in 1993 by Didier Pourcel and his team at Gribouille. It involved "cloning" the body and face of French comedian Richard Bohringer, and then animating it with still-nascent motion-capture tools.
    </div>

    <div class = "block" id = "header">
        <h2>Virtual Reality</h2>
    </div> 
    <div class = "block var1 var2" id = "paragraph">
        <div class="image-container">
            <img src = "imgs/image6.jpg">
        </div>
        Virtual reality (VR) is a simulated experience that employs pose tracking and 3D near-eye displays to give the user an immersive feel of a virtual world. Applications of virtual reality include entertainment (particularly video games), education (such as medical or military training) and business (such as virtual meetings). Other distinct types of VR-style technology include augmented reality and mixed reality, sometimes referred to as extended reality or XR, although definitions are currently changing due to the nascence of the industry. Currently, standard virtual reality systems use either virtual reality headsets or multi-projected environments to generate some realistic images, sounds and other sensations that simulate a user's physical presence in a virtual environment. A person using virtual reality equipment is able to look around the artificial world, move around in it, and interact with virtual features or items. The effect is commonly created by VR headsets consisting of a head-mounted display with a small screen in front of the eyes, but can also be created through specially designed rooms with multiple large screens. Virtual reality typically incorporates auditory and video feedback, but may also allow other types of sensory and force feedback through haptic technology.
    </div>

    <div class = "block" id = "header">
        <h2>Hardware</h2>
    </div> 
    <div class = "block var1 var2" id = "paragraph">
        <div class="image-container">
            <img src = "imgs/image11.gif">
        </div>
        Modern virtual reality headset displays are based on technology developed for smartphones including gyroscopes and motion sensors for tracking head, body, and hand positions; small HD screens for stereoscopic displays; and small, lightweight, and fast computer processors. These components led to relative affordability for independent VR developers, and led to the 2012 Oculus Rift Kickstarter offering the first independently developed VR headset. Independent production of VR images and video has increased alongside the development of affordable omnidirectional cameras, also known as 360-degree cameras or VR cameras, that have the ability to record 360 interactive photography, although at relatively low resolutions or in highly compressed formats for online streaming of 360 video. In contrast, photogrammetry is increasingly used to combine several high-resolution photographs for the creation of detailed 3D objects and environments in VR applications. To create a feeling of immersion, special output devices are needed to display virtual worlds. Well-known formats include head-mounted displays or the CAVE. In order to convey a spatial impression, two images are generated and displayed from different perspectives (stereo projection). There are different technologies available to bring the respective image to the right eye. A distinction is made between active (e.g. shutter glasses) and passive technologies (e.g. polarizing filters or Infitec). In order to improve the feeling of immersion, wearable multi-string cables offer haptics to complex geometries in virtual reality. These strings offer fine control of each finger joint to simulate the haptics involved in touching these virtual geometries.
        <br>
        <br>
        <div class="image-container" style="float:left;margin: 0 20px 5px 0">
            <img src = "imgs/image12.jpg">
        </div>
        Special input devices are required for interaction with the virtual world. Some of the most common input devices are motion controllers and optical tracking sensors. In some cases, wired gloves are used. Controllers typically use optical tracking systems (primarily infrared cameras) for location and navigation, so that the user can move freely without wiring. Some input devices provide the user with force feedback to the hands or other parts of the body, so that the human being can orientate himself in the three-dimensional world through haptics and sensor technology as a further sensory sensation and carry out realistic simulations. This allows for the viewer to have a sense of direction in the artificial landscape. Additional haptic feedback can be obtained from omnidirectional treadmills (with which walking in virtual space is controlled by real walking movements) and vibration gloves and suits. Virtual reality cameras can be used to create VR photography using 360-degree panorama videos. 360-degree camera shots can be mixed with virtual elements to merge reality and fiction through special effects. Virtual reality cameras can be used as a stepping stone to make realistic holographic displays these cameras can be used to cover every angle of the needed experience. VR cameras are available in various formats, with varying numbers of lenses installed in the camera.
    </div>

    <div class = "block" id = "header">
        <h2>Software</h2>
    </div>  
    <div class = "block var1 var2" id = "paragraph">
        The Virtual Reality Modelling Language (VRML), first introduced in 1994, was intended for the development of "virtual worlds" without dependency on headsets. The Web3D consortium was subsequently founded in 1997 for the development of industry standards for web-based 3D graphics. The consortium subsequently developed X3D from the VRML framework as an archival, open-source standard for web-based distribution of VR content. WebVR is an experimental JavaScript application programming interface (API) that provides support for various virtual reality devices, such as the HTC Vive, Oculus Rift, Google Cardboard, or OSVR, in a web browser.
    </div>
    
    <div class = "block" id = "header">
        <h2>Augmented Reality</h2>
    </div>  
    <div class = "block var1 var2" id = "paragraph">
        <div class="image-container">
            <img src = "imgs/image3.png"style="margin-bottom: 20px;">
            <img src = "imgs/image7.jpg"style="float:right;">
        </div>
        Augmented reality (AR) is an interactive experience that combines the real world and computer-generated content. The content can span multiple sensory modalities, including visual, auditory, haptic, somatosensory, and olfactory. AR can be defined as a system that incorporates three basic features: a combination of real and virtual worlds, real-time interaction, and accurate 3D registration of virtual and real objects. The overlaid sensory information can be constructive (i.e. additive to the natural environment), or destructive (i.e. masking of the natural environment). This experience is seamlessly interwoven with the physical world such that it is perceived as an immersive aspect of the real environment. In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one.
        Augmented reality is largely synonymous with mixed reality. There is also overlap in terminology between extended reality and computer-mediated reality.
        <br>
        <br>
        The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment. The earliest functional AR systems that provided immersive mixed reality experiences for users were invented in the early 1990s, starting with the Virtual Fixtures system developed at the U.S. Air Force's Armstrong Laboratory in 1992. Commercial augmented reality experiences were first introduced in entertainment and gaming businesses. Subsequently, augmented reality applications have spanned commercial industries such as education, communications, medicine, and entertainment. In education, content may be accessed by scanning or viewing an image with a mobile device or by using markerless AR techniques.
        Augmented reality is used to enhance natural environments or situations and offers perceptually enriched experiences. With the help of advanced AR technologies (e.g. adding computer vision, incorporating AR cameras into smartphone applications, and object recognition) the information about the surrounding real world of the user becomes interactive and digitally manipulated. Information about the environment and its objects is overlaid on the real world. This information can be virtual. Augmented Reality is any experience which is artificial and which adds to the already existing reality. or real, e.g. seeing other real sensed or measured information such as electromagnetic radio waves overlaid in exact alignment with where they actually are in space. Augmented reality also has a lot of potential in the gathering and sharing of tacit knowledge. Augmentation techniques are typically performed in real-time and in semantic contexts with environmental elements. Immersive perceptual information is sometimes combined with supplemental information like scores over a live video feed of a sporting event. This combines the benefits of both augmented reality technology and heads up display technology (HUD).
    </div>
    
    <div class = "block" id = "header">
        <h2>Comparison with Virtual Reality</h2>
    </div>  
    <div class = "block var1 var2" id = "paragraph">
        In virtual reality (VR), the users' perception of reality is completely based on virtual information. In augmented reality (AR) the user is provided with additional computer- generated information within the data collected from real life that enhances their perception of reality. For example, in architecture, VR can be used to create a walk-through simulation of the inside of a new building; and AR can be used to show a building's structures and systems super-imposed on a real-life view. Another example is through the use of utility applications. Some AR applications, such as Augment, enable users to apply digital objects into real environments, allowing businesses to use augmented reality devices as a way to preview their products in the real world. Similarly, it can also be used to demo what products may look like in an environment for customers, as demonstrated by companies such as Mountain Equipment Co-op or Lowe's who use augmented reality to allow customers to preview what their products might look like at home through the use of 3D models.
Augmented reality (AR) differs from virtual reality (VR) in the sense that in AR part of the surrounding environment is 'real' and AR is just adding layers of virtual objects to the real environment. On the other hand, in VR the surrounding environment is completely virtual and computer generated. A demonstration of how AR layers objects onto the real world can be seen with augmented reality games. WallaMe is an augmented reality game application that allows users to hide messages in real environments, utilizing geolocation technology in order to enable users to hide messages wherever they may wish in the world. Such applications have many uses in the world, including in activism and artistic expression.
    </div>


    <div class = "block" id = "header">
        <h2>Sources</h2>
    </div>  

    <div class = "block" id = "paragraph">
        Rolfe, J. M. and Staples, K.J. (May 27, 1988). Flight Simulation (Cambridge Aerospace Series, Series Number 1). New York: Cambridge University Press. ISBN 978-0521357517.
<br>Carlson, Wayne (20 June 2017). "Computer Graphics and Animation: A Retrospective Overview". Ohio State University. p. 13.2.
<br>Begault 1994, p. 212.
<br>Computer-generated images influence trial results The Conversation, 31 October 2013
<br>Kassin, S. M. (1997). "Computer-animated Display and the Jury: Facilitative and Prejudicial Effects". Law and Human Behavior. 40 (3): 269–281. doi:10.1023/a:1024838715221. S2CID 145311101. [2]
<br>David Noonan, Peter Mountney, Daniel Elson, Ara Darzi and Guang-Zhong Yang. A Stereoscopic Fibroscope for Camera Motion and 3-D Depth Recovery During Minimally Invasive Surgery. In proc ICRA 2009, pp. 4463–68. http://www.sciweavers.org/external.php?u=http%3A%2F%2Fwww.doc.ic.ac.uk%2F%7Epmountne%2Fpublications%2FICRA%25202009.pdf&p=ieee
<br>Yamane, Katsu, and Jessica Hodgins. "Simultaneous tracking and balancing of humanoid robots for imitating human motion capture data." Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International Conference on. IEEE, 2009.
<br>NY Castings, Joe Gatt, Motion Capture Actors: Body Movement Tells the Story Archived 2014-07-03 at the Wayback Machine, Accessed June 21, 2014
<br>Andrew Harris Salomon, Feb. 22, 2013, Backstage Magazine, Growth In Performance Capture Helping Gaming Actors Weather Slump, Accessed June 21, 2014, "..But developments in motion-capture technology, as well as new gaming consoles expected from Sony and Microsoft within the year, indicate that this niche continues to be a growth area for actors. And for those who have thought about breaking in, the message is clear: Get busy...."
<br>Ben Child, 12 August 2011, The Guardian, Andy Serkis: why won't Oscars go ape over motion-capture acting? Star of Rise of the Planet of the Apes says performance capture is misunderstood and its actors deserve more respect, Accessed June 21, 2014
<br>Hugh Hart, January 24, 2012, Wired magazine, When will a motion capture actor win an Oscar?, Accessed June 21, 2014, "...the Academy of Motion Picture Arts and Sciences' historic reluctance to honor motion-capture performances ... Serkis, garbed in a sensor-embedded Lycra body suit, quickly mastered the then-novel art and science of performance-capture acting. ..."
<br>Wu, Hsin-Kai; Lee, Silvia Wen-Yu; Chang, Hsin-Yi; Liang, Jyh-Chong (March 2013). "Current status, opportunities and challenges of augmented reality in education...". Computers & Education. 62: 41–49. doi:10.1016/j.compedu.2012.10.024. S2CID 15218665.
<br>Kelly, Kevin (April 2016). "The Untold Story of Magic Leap, the World's Most Secretive Startup". WIRED. Retrieved 13 March 2017.
<br>"Stereoscopic Display - an overview | ScienceDirect Topics". www.sciencedirect.com. Retrieved 19 October 2022.
<br>Fang, Cathy; Zhang, Yang; Dworman, Matthew; Harrison, Chris (21 April 2020). "Wireality: Enabling Complex Tangible Geometries in Virtual Reality with Worn Multi-String Haptics". Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. CHI '20. Honolulu, HI, USA: Association for Computing Machinery. pp. 1–10. doi:10.1145/3313831.3376470. ISBN 978-1-4503-6708-0. S2CID 218483027.
<br>University, Stanford (12 November 2021). "Using AI to create better virtual reality experiences". Stanford News. Retrieved 5 December 2023.
<br>Kuhn, Thomas. "Wie Virtual-Reality-Brillen die Arbeit verändern". WirtschaftsWoche. Retrieved 18 November 2020.
<br>Cipresso, Pietro; Giglioli, Irene Alice Chicchi; Raya, iz; Riva, Giuseppe (7 December 2011). "The Past, Present, and Future of Virtual and Augmented Reality Research: A Network and Cluster Analysis of the Literature". Frontiers in Psychology. 9: 2086. doi:10.3389/fpsyg.2018.02086. PMC 6232426. PMID 30459681.
<br>Wu, Hsin-Kai; Lee, Silvia Wen-Yu; Chang, Hsin-Yi; Liang, Jyh-Chong (March 2013). "Current status, opportunities and challenges of augmented reality in education...". Computers & Education. 62: 41–49. doi:10.1016/j.compedu.2012.10.024. S2CID 15218665.
<br>Rosenberg, Louis B. (1992). "The Use of Virtual Fixtures as Perceptual Overlays to Enhance Operator Performance in Remote Environments". Archived from the original on 10 July 2019.
<br>Steuer,"Defining virtual reality: Dimensions Determining Telepresence". Archived from the original on 17 July 2022. Retrieved 27 November 2018., Department of Communication, Stanford University. 15 October 1993.
<br>Introducing Virtual Environments Archived 21 April 2016 at the Wayback Machine National Center for Supercomputing Applications, University of Illinois.
<br>Rosenberg, L.B. (1993). "Virtual fixtures: Perceptual tools for telerobotic manipulation". Proceedings of IEEE virtual reality Annual International Symposium. pp. 76–82. doi:10.1109/VRAIS.1993.380795. ISBN 0-7803-1363-1. S2CID 9856738.
<br>Dupzyk, Kevin (6 September 2016). "I Saw the Future Through Microsoft's Hololens". Popular Mechanics.
<br>Arai, Kohei, ed. (2022), "Augmented Reality: Reflections at Thirty Years", Proceedings of the Future Technologies Conference (FTC) 2021, Volume 1, Lecture Notes in Networks and Systems, Cham: Springer International Publishing, vol. 358, pp. 1–11, doi:10.1007/978-3-030-89906-6_1, ISBN 978-3-030-89905-9, S2CID 239881216
<br>Moro, Christian; Birt, James; Stromberga, Zane; Phelps, Charlotte; Clark, Justin; Glasziou, Paul; Scott, Anna Mae (2021). "Virtual and Augmented Reality Enhancements to Medical and Science Student Physiology and Anatomy Test Performance: A Systematic Review and Meta-Analysis". Anatomical Sciences Education. 14 (3): 368–376. doi:10.1002/ase.2049. ISSN 1935-9772. PMID 33378557. S2CID 229929326.
<br>"How to Transform Your Classroom with Augmented Reality - EdSurge News". 2 November 2015.
<br>Crabben, Jan van der (16 October 2018). "Why We Need More Tech in History Education". ancient.eu. Archived from the original on 23 October 2018. Retrieved 23 October 2018.
<br>Dargan, Shaveta; Bansal, Shally; Mittal, Ajay; Kumar, Krishan (20 October 2022). "Augmented Reality: A Comprehensive Review". Archives of Computational Methods in Engineering. Retrieved 27 February 2024.
<br>Hegde, Naveen (19 March 2023). "What is Augmented Reality". Codegres. Retrieved 19 March 2023.
<br>Chen, Brian (25 August 2009). "If You're Not Seeing Data, You're Not Seeing". Wired. Retrieved 18 June 2019.
<br>Maxwell, Kerry. "Augmented Reality". macmillandictionary.com. Retrieved 18 June 2019.
<br>"Augmented Reality (AR)". augmentedrealityon.com. Archived from the original on 5 April 2012. Retrieved 18 June 2019.
<br>Azuma, Ronald (August 1997). "A Survey of Augmented Reality" (PDF). Presence: Teleoperators and Virtual Environments. MIT Press. 6 (4): 355–385. doi:10.1162/pres.1997.6.4.355. S2CID 469744. Retrieved 2 June 2021.
<br>"Phenomenal Augmented Reality, IEEE Consumer Electronics, Volume 4, No. 4, October 2015, cover+pp92-97" (PDF).
<br>Time-frequency perspectives, with applications, in Advances in Machine Vision, Strategies and Applications, World Scientific Series in Computer Science: Volume 32, C Archibald and Emil Petriu, Cover + pp 99–128, 1992.
<br>Mann, Steve; Feiner, Steve; Harner, Soren; Ali, Mir Adnan; Janzen, Ryan; Hansen, Jayse; Baldassi, Stefano (15 January 2015). "Wearable Computing, 3D Aug* Reality, Photographic/Videographic Gesture Sensing, and Veillance". Proceedings of the Ninth International Conference on Tangible, Embedded, and Embodied Interaction - TEI '14. ACM. pp. 497–500. doi:10.1145/2677199.2683590. ISBN 9781450333054. S2CID 12247969.
<br>Carmigniani, Julie; Furht, Borko; Anisetti, Marco; Ceravolo, Paolo; Damiani, Ernesto; Ivkovic, Misa (1 January 2011). "Augmented reality technologies, systems and applications". Multimedia Tools and Applications. 51 (1): 341–377. doi:10.1007/s11042-010-0660-6. ISSN 1573-7721. S2CID 4325516.
<br>Ma, Minhua; C. Jain, Lakhmi; Anderson, Paul (2014). Virtual, Augmented Reality and Serious Games for Healthcare 1. Springer Publishing. p. 120. ISBN 978-3-642-54816-1.
<br>Marvin, Rob (16 August 2016). "Augment Is Bringing the AR Revolution to Business". PC Mag. Retrieved 23 February 2021.
<br>Stamp, Jimmy (30 August 2019). "Retail is getting reimagined with augmented reality". The Architect's Newspaper. Archived from the original on 15 November 2019.
<br>Mahmood 2019-04-12T11:30:27Z, Ajmal (12 April 2019). "The future is virtual - why AR and VR will live in the cloud". TechRadar. Retrieved 12 December 2019.

    </div>
    
    
</body>
</html>